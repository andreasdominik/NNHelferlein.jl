var documenterSearchIndex = {"docs":
[{"location":"api/","page":"API Reference","title":"API Reference","text":"API doc of all exported functions are listed here:","category":"page"},{"location":"api/#Chains","page":"API Reference","title":"Chains","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"DNN\nadd_layer!\nprint_network","category":"page"},{"location":"api/#NNHelferlein.DNN","page":"API Reference","title":"NNHelferlein.DNN","text":"abstract type DNN end\n\nMother type for DNN hierarchy with implementation for a chain of layers.\n\nSignatures:\n\n(m::DNN)(x) = (for l in m.layers; x = l(x); end; x)\n(m::DNN)(x,y) = m(x,y)\n(m::DNN)(d::Knet.Data) = mean( m(x,y) for (x,y) in d)\n(m::DNN)(d::Tuple) = mean( m(x,y) for (x,y) in d)\n(m::DNN)(d::NNHelferlein.DataLoader) = mean( m(x,y) for (x,y) in d)\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.add_layer!","page":"API Reference","title":"NNHelferlein.add_layer!","text":"add_layer!(n::NNHelferlein.DNN, l)\n\nAdd a layer l or a chain to a model n. The layer is always added  at the end of the chains. \n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.print_network","page":"API Reference","title":"NNHelferlein.print_network","text":"function print_network(mdl::DNN)\n\nPrint a network summary of any model of Type DNN. If the model has a field layers, the summary of all included layers will be printed recursively.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Classifier\nRegressor\nChain\nVAE","category":"page"},{"location":"api/#NNHelferlein.Classifier","page":"API Reference","title":"NNHelferlein.Classifier","text":"struct Classifier <: DNN\n\nClassifier with nll loss.\n\nSignatures:\n\n(m::Classifier)(x,y) = nll(m(x), y)\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.Regressor","page":"API Reference","title":"NNHelferlein.Regressor","text":"struct Regressor\n\nRegression network with square loss.\n\nSignatures:\n\n(m::Regression)(x,y) = sum(abs2.( m(x) - y))\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.Chain","page":"API Reference","title":"NNHelferlein.Chain","text":"struct Chain\n\nSimple wrapper to chain layers and execute them one after another.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.VAE","page":"API Reference","title":"NNHelferlein.VAE","text":"struct VAE\n\nType for a generic variational autoencoder.\n\nConstructor:\n\nVAE(encoder, decoder)\n\nSeparate predefinded chains (ideally, but not necessarily of type Chain)  for encoder and decoder must be specified. The VAE needs the 2 parameters mean and variance to define the distribution of each code-neuron in the bottleneck-layer. In consequence the encoder output must be 2 times  the size of the decoder input (in case of dense layers: if encoder output is a 8-value vector, 4 codes are defined and the decoder input is a 4-value vector; in case of convolutional layers the number of encoder output channels must be 2 times the number of the encoder input channels - see the examples). \n\nSignatures:\n\n(vae::VAE)(x)\n(vae::VAE)(x,y)\n\nCalled with one argument, predict will be executed;  with two arguments (args x and y should be identical for the autoencoder) the loss will be returned.    \n\nDetails:\n\nThe loss is calculated as the sum of element-wise error squares plus the Kullback-Leibler-Divergence to adapt the distributions of the bottleneck codes:\n\nmathcalL = frac12 sum_i=1^n_outputs (t_i-o_i)^2 - \n               frac12 sum_j=1^n_codes(1 + lnsigma_c_j^2-mu_c_j^2-sigma_c_j^2) \n\nOutput of the autoencoder is cropped to the size of input before loss calculation (and before prediction); i.e. the output has always the same dimensions as the input, even if the last layer generates a bigger shape.\n\n\n\n\n\n","category":"type"},{"location":"api/#Layers","page":"API Reference","title":"Layers","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Layer","category":"page"},{"location":"api/#NNHelferlein.Layer","page":"API Reference","title":"NNHelferlein.Layer","text":"abstract type Layer end\n\nMother type for layers hierarchy.\n\n\n\n\n\n","category":"type"},{"location":"api/#Fully-connected-layers","page":"API Reference","title":"Fully connected layers","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Dense\nLinear\nEmbed","category":"page"},{"location":"api/#NNHelferlein.Dense","page":"API Reference","title":"NNHelferlein.Dense","text":"struct Dense  <: Layer\n\nDefault Dense layer.\n\nConstructors:\n\nDense(w, b, actf): default constructor\nDense(i::Int, j::Int; actf=sigm): layer of j neurons with       i inputs.\nDense(h5::HDF5.File, group::String; trainable=false, actf=sigm):\nDense(h5::HDF5.File, kernel::String, bias::String;       trainable=false, actf=sigm): layer       imported from a hdf5-file from tensorflow with the       hdf-object hdfo and the group name group.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.Linear","page":"API Reference","title":"NNHelferlein.Linear","text":"struct Linear  <: Layer\n\nAlmost standard dense layer, but functionality inspired by the TensorFlow-layer:\n\ncapable to work with input tensors of any number of dimensions\ndefault activation function identity\noptionally without biases.\n\nThe shape of the input tensor is preserved; only the size of the first dim is changed from in to out.\n\nConstructors:\n\nLinear(i::Int, j::Int; bias=true, actf=identity) where i is fan-in       and j is fan-out.\n\nKeyword arguments:\n\nbias=true: if false biases are fixed to 0.0\nactf=identity: activation function.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.Embed","page":"API Reference","title":"NNHelferlein.Embed","text":"struct Embed <: Layer\n\nSimple type for an embedding layer to embed a virtual onehot-vector into a smaller number of neurons by linear combination. The onehot-vector is virtual, because not the vector, but only the index of the \"one\" in the vector has to be provided as Integer value (or a minibatch of integers).\n\nFields:\n\nw\nactf\n\nConstructors:\n\nEmbed(v,d; actf=identity): with   vocab size v, embedding depth d and default activation function idendity.\n\nSignatures:\n\n(l::Embed)(x) = l.actf.(w[:,x]) default embedding of input tensor x.\n\nValue:\n\nThe embedding is constructed by adding a first dimension to the input tensor with number of rows = embedding depth. If x is a column vector, the value is a matrix. If x is as row-vector or a matrix, the value is a 3-d array, etc.\n\n\n\n\n\n","category":"type"},{"location":"api/#Convolutional","page":"API Reference","title":"Convolutional","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Conv\nDeConv\nPool\nUnPool","category":"page"},{"location":"api/#NNHelferlein.Conv","page":"API Reference","title":"NNHelferlein.Conv","text":"struct Conv  <: Layer\n\nDefault Conv layer.\n\nConstructors:\n\nConv(w, b, padding, actf): default constructor\nConv(w1::Int, w2::Int,  i::Int, o::Int; actf=relu; kwargs...): layer with   o kernels of size (w1,w2) for an input of i layers.\nConv(h5::HDF5.File, group::String; trainable=false, actf=relu):\nConv(h5::HDF5.File, group::String; trainable=false, actf=relu): layer       imported from a hdf5-file from tensorflow with the       hdf-object hdfo and the group name group.\n\nKeyword arguments:\n\npadding=0: the number of extra zeros implicitly concatenated       at the start and end of each dimension.\nstride=1: the number of elements to slide to reach the next filtering window.\ndilation=1: dilation factor for each dimension.\n... See the Knet documentation for Details:       https://denizyuret.github.io/Knet.jl/latest/reference/#Convolution-and-Pooling.       All keywords to the Knet function conv4() are supported.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.DeConv","page":"API Reference","title":"NNHelferlein.DeConv","text":"struct DeConv  <: Layer\n\nDefault deconvolution layer.\n\nConstructors:\n\nDeConv(w, b, actf, kwargs...): default constructor\nConv(w1::Int, w2::Int,  i::Int, o::Int; actf=relu, kwargs...): layer with   o kernels of size (w1,w2) for an input of i channels.\nConv(h5::HDF5.File, group::String; trainable=false, actf=relu):\nConv(h5::HDF5.File, group::String; trainable=false, actf=relu): layer       imported from a hdf5-file from tensorflow with the       hdf-object hdfo and the group name group.\n\nKeyword arguments:\n\npadding=0: the number of extra zeros implicitly concatenated       at the start and end of each dimension (applied to the output).\nstride=1: the number of elements to slide to reach the next filtering window       (applied to the output).\n... See the Knet documentation for Details:       https://denizyuret.github.io/Knet.jl/latest/reference/#Convolution-and-Pooling.       All keywords to the Knet function deconv4() are supported.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.Pool","page":"API Reference","title":"NNHelferlein.Pool","text":"struct Pool <: Layer\n\nPooling layer.\n\nConstructors:\n\nPool(;kwargs...): max pooling; without kwargs, 2x2-pooling       is performed.\n\nKeyword arguments:\n\nwindow=2: pooling window size (same for both directions)\n...: See the Knet documentation for Details:       https://denizyuret.github.io/Knet.jl/latest/reference/#Convolution-and-Pooling.       All keywords to the Knet function pool are supported.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.UnPool","page":"API Reference","title":"NNHelferlein.UnPool","text":"struct UnPool <: Layer\n\nUnpooling layer.\n\nConstructors:\n\nUnPool(;kwargs...): user-defined unpooling\n\n\n\n\n\n","category":"type"},{"location":"api/#Recurrent","page":"API Reference","title":"Recurrent","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"RecurrentUnit\nRecurrent\nget_hidden_states\nget_cell_states\nset_hidden_states!\nset_cell_states!\nreset_hidden_states!\nreset_cell_states!","category":"page"},{"location":"api/#NNHelferlein.RecurrentUnit","page":"API Reference","title":"NNHelferlein.RecurrentUnit","text":"abstract type RecurrentUnit end\n\nSupertype for all recurrent unit types. Self-defined recurrent units which are a child of RecurrentUnit can be used inside the 'Recurrent' layer.\n\nInterface\n\nAll subtypes of RecurrentUnit must provide the followning:\n\na constructor with signature Type(n_inputs, n_units; kwargs) and   arbitrary keyword arguments.\nan implementation of signature (o::Recurrent)(x)   where x is a 3d- or 2d-array of shape [fan-in, mb-size, 1] or    [fan-in, mb-size].   The function must return the result of one forward    computation for one step and return the hidden state   and set the internal fields h and optionally c.\na field h (to store the last hidden state)\nan optional field c, if the cell state is to be stored   such as in a lstm unit.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.Recurrent","page":"API Reference","title":"NNHelferlein.Recurrent","text":"struct Recurrent <: Layer\n\nOne layer RNN that works with minimatches of (time) series data. minibatch can be a 2- or 3-dimensional Array. If 2-d, inputs for one step are in one column and the Array has as many colums as steps. If 3-d, the last dimension iterates the samples of the minibatch.\n\nResult is an array matrix with the output of the units of all steps for all smaples of the minibatch (with model depth as first and samples of the minimatch as last dimension).\n\nConstructors:\n\nRecurrent(n_inputs::Int, n_units::Int; u_type=:lstm, \n          bidirectional=false, allow_mask=false, o...)\n\nn_inputs: number of inputs\nn_units:  number of units \nu_type :  unit type can be one of the Knet unit types       (:relu, :tanh, :lstm, :gru) or a type which must be a        subtype of RecurrentUnit and fullfill the repective interface        (see the docs for RecurentUnit).\nbidirectional=false: if true, 2 layers of n_units units will be defined       and run in forward and backward direction respectively. The hidden       state is [2*n_units*mb] or [2*n_units,steps,mb] id return_all==true.\nallow_mask=false: if maskin is allowed a slower algorithm is used to be        able to ignore any masked step. Arbitrary sequence positions may be        masked for any sequence.\n\nAny keyword argument of Knet.RNN or  a self-defined RecurrentUnit type may be provided.\n\nSignatures:\n\nfunction (rnn::Recurrent)(x; c=nothing, h=nothing, return_all=false, \n          mask=nothing)\n\nThe layer is called either with a 2-dimensional array of the shape [fan-in, steps]  or a 3-dimensional array of [fan-in, steps, batchsize].\n\nArguments:\n\nc=nothing, h=nothing: inits the hidden and cell state.   If nothing,  states h or c keep their values.    If c=0 or h=0, the states are reseted to 0;   otherwise an array of states of the correct dimensions can be supplied    to be used as initial states.\nreturn_all=true: if true an array with all hidden states of all steps    is returned (size is [units, time-steps, minibatch]).   Otherwise only the hidden states of the last step is returned   ([units, minibatch]).\nmask: optional mask for the input sequence minibatch of shape    [steps, minibatch]. Values in the mask must be 1.0 for masked positions   or 0.0 otherwise and of type Float32 or CuArray{Float32} for GPU context.    Appropriate masks can be generated with the NNHelferlein function    mk_padding_mask().\n\nBidirectional layers can be constructed by specifying bidirectional=true, if the unit-type supports it (Knet.RNN does.).  Please be aware that the actual number of units is 2n_units for  bidirectional layers and the output dimension is [2units, steps, mb] or [2*units, mb].\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.get_hidden_states","page":"API Reference","title":"NNHelferlein.get_hidden_states","text":"function get_hidden_states(l::<RNN_Type>; flatten=true)\n\nReturn the hidden states of one or more layers of an RNN. <RNN_Type> is one of NNHelderlein.Recurrent, Knet.RNN.\n\nArguments:\n\nflatten=true: if the states tensor is 3d with a 3rd dim > 1, the        array is transformed to [units, mb, 1] to represent all current states       after the last step.\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.get_cell_states","page":"API Reference","title":"NNHelferlein.get_cell_states","text":"function get_cell_states(l::<RNN_Type>; unbox=true, flatten=true)\n\nReturn the cell states of one or more layers of an RNN only if it is a LSTM.\n\nArguments:\n\nunbox=true: By default, c is unboxed when called in @diff context (while AutoGrad        is recording) to avoid unwanted dependencies of the computation graph       s2s.attn(reset=true)       (backprop should run via the hidden states, not the cell states).\nflatten=true: if the states tensor is 3d with a 3rd dim > 1, the        array is transformed to [units, mb, 1] to represent all current states       after the last step.\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.set_hidden_states!","page":"API Reference","title":"NNHelferlein.set_hidden_states!","text":"function set_hidden_states!(l::<RNN_Type>, h)\n\nSet the hidden states of one or more layers of an RNN to h.\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.set_cell_states!","page":"API Reference","title":"NNHelferlein.set_cell_states!","text":"function set_cell_states!(l::<RNN_Type>, c)\n\nSet the cell states of one or more layers of an RNN to c.\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.reset_hidden_states!","page":"API Reference","title":"NNHelferlein.reset_hidden_states!","text":"function reset_hidden_states!(l::<RNN_Type>)\n\nReset the hidden states of one or more layers of an RNN to 0.\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.reset_cell_states!","page":"API Reference","title":"NNHelferlein.reset_cell_states!","text":"function reset_cell_states!(l::<RNN_Type>)\n\nReset the cell states of one or more layers of an RNN to 0.\n\n\n\n\n\n","category":"function"},{"location":"api/#Others","page":"API Reference","title":"Others","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Flat\nPyFlat\nSoftmax\nDropout\nBatchNorm\nLayerNorm","category":"page"},{"location":"api/#NNHelferlein.Flat","page":"API Reference","title":"NNHelferlein.Flat","text":"struct Flat <: Layer\n\nDefault flatten layer.\n\nConstructors:\n\nFlat(): with no options.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.PyFlat","page":"API Reference","title":"NNHelferlein.PyFlat","text":"struct PyFlat <: Layer\n\nFlatten layer with optional Python-stype flattening (row-major). This layer can be used if pre-trained weight matrices from tensorflow are applied after the flatten layer.\n\nConstructors:\n\nPyFlat(; python=true): if true, row-major flatten is performed.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.Softmax","page":"API Reference","title":"NNHelferlein.Softmax","text":"struct Softmax <: Layer\n\nSimple softmax layer to compute softmax probabilities.\n\nConstructors:\n\nSoftmax()\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.Dropout","page":"API Reference","title":"NNHelferlein.Dropout","text":"struct Dropout <: Layer\n\nDropout layer. Implemented with help of Knet's dropout() function that evaluates AutoGrad.recording() to detect if in training or inprediction. Dropouts are applied only if prediction.\n\nConstructors:\n\nDropout(p) with the dropout rate p.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.BatchNorm","page":"API Reference","title":"NNHelferlein.BatchNorm","text":"struct BatchNorm <: Layer\n\nBatchnormalisation layer. Implemented with help of Knet's batchnorm() function that evaluates AutoGrad.recording() to detect if in training or in prediction. In training the moments are updated to record the running averages; in prediction the moments are applied, but not modified.\n\nIn addition, optional trainable factor a and bias b are applied:\n\ny = a cdot frac(x - mu)(sigma + epsilon) + b\n\nConstructors:\n\nBatchnom(; trainable=false, channels=0) will initialise       the moments with Knet.bnmoments() and       trainable parameters a and b only if       trainable==true (in this case, the number of channels must       be defined - for CNNs this is the number of feature maps).\n\nDetails:\n\n2d, 4d and 5d inputs are supported. Mean and variance are computed over dimensions (2), (1,2,4) and (1,2,3,5) for 2d, 4d and 5d arrays, respectively.\n\nIf trainable=true and channels != 0, trainable parameters a and b will be initialised for each channel.\n\nIf trainable=true and channels == 0 (i.e. Batchnom(trainable=true)), the params a and b are not initialised by the constructor. Instead, the number of channels is inferred when the first minibatch is normalised as: 2d: size(x)[1] 4d: size(x)[3] 5d: size(x)[4] or 0 otherwise.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.LayerNorm","page":"API Reference","title":"NNHelferlein.LayerNorm","text":"struct LayerNorm  <: Layer\n\nSimple layer normalisation (inspired by TFs LayerNormalization). Implementation is from Deniz Yuret's answer to feature request 429 (https://github.com/denizyuret/Knet.jl/issues/492).\n\nThe layer performs a normalisation within each sample, not batchwise. Normalisation is modified by two trainable parameters a and b (variance and mean) added to every value of the sample vector.\n\nConstructors:\n\nLayertNorm(depth; eps=1e-6):  depth is the number       of activations for one sample of the layer.\n\nSignatures:\n\nfunction (l::LayerNorm)(x; dims=1): normalise x along the given dimensions.       The size of the specified dimension must fit with the initialised depth.\n\n\n\n\n\n","category":"type"},{"location":"api/#Attention-Mechanisms","page":"API Reference","title":"Attention Mechanisms","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"AttentionMechanism\nAttnBahdanau\nAttnLuong\nAttnDot\nAttnLocation\nAttnInFeed","category":"page"},{"location":"api/#NNHelferlein.AttentionMechanism","page":"API Reference","title":"NNHelferlein.AttentionMechanism","text":"abstract type AttentionMechanism\n\nAttention mechanisms follow the same interface and common signatures.\n\nIf possible, the algorithm allows precomputing of the projections of the context vector generated by the encoder in a encoder-decoder-architecture (i.e. in case of an RNN encoder the accumulated encoder hidden states).\n\nBy default attention scores are scaled according to Vaswani et al., 2017 (Vaswani et al., Attention Is All You Need, CoRR, 2017).\n\nAll algorithms use soft attention.\n\nConstructors:\n\nAttn*Mechanism*(dec_units, enc_units; scale=true)\nAttn*Mechanism*(units; scale=true)\n\nThe one-argument version can be used, if encoder dimensions and decoder dimensions are the same.\n\nCommon Signatures:\n\nfunction (attn::AttentionMechanism)(h_t, h_enc; reset=false, mask=nothing)\nfunction (attn::AttentionMechanism)(; reset=false)\n\nArguments:\n\nh_t:    decoder hidden state. If h_t is a vector, its length           equals the number of decoder units. If it is a matrix,           h_t includes the states for a minibatch of samples and has           the size [units, mb].\nh_enc:  encoder hidden states, 2d or 3d. If h_enc is a           matrix [units, steps] with the hidden states of all encoder steps.           If 3d: [units, mb, steps] encoder states for all minibatches.\nmask:   optional mask (e.g. padding mask) for masking input steps           of dimensions [mb, steps]. Attentions factors for masked steps            will be set to 0.0.\nreset=false: If the keyword argument is set to true, projections of           the encoder states are computed. By default projections are           stored in the object and reused until the object is resetted.           For attention mechanisms that don't allow precomputation           the argument is ignored.\n\nThe short form (::AttentionMechanism)(reset=true) can be used to reset the precomputed projections.\n\nReturn values\n\nAll functions return c and α where α is a matrix of size [mb,steps] with the attention factors for each step and minibatch. c is a matrix of size [units, mb] with the context vector for each sample of the minibatch, calculated as the α-weighted sum of all encoder hidden states h_enc for each minibatch.\n\nAttention Mechanisms:\n\nAll attention mechanisms calculate attention factors α from scores derived from projections of the encoder hidden states:\n\nalpha = mathrmsoftmax(mathrmscore(h_ench_t) cdot 1sqrtn))\n\nAttention mechanisms implemented:\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.AttnBahdanau","page":"API Reference","title":"NNHelferlein.AttnBahdanau","text":"mutable struct AttnBahdanau <: AttentionMechanism\n\nBahdanau-style (additive, concat) attention mechanism according to the paper:\n\nD. Bahdanau, KH. Co, Y. Bengio, Neural Machine Translation by jointlylearning to align and translate, ICLR, 2015.\n\nmathrmscore(h_th_enc) = v_a^topcdottanh(Wh_th_enc)\n\nConstructors:\n\nAttnBahdanau(dec_units, enc_units; scale=true)\nAttnBahdanau(units; scale=true)\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.AttnLuong","page":"API Reference","title":"NNHelferlein.AttnLuong","text":"mutable struct AttnLuong <: AttentionMechanism\n\nLuong-style (multiplicative) attention mechanism according to the paper (referred as General-type attention): M.-T. Luong, H. Pham, C.D. Manning, Effective Approaches to Attention-based Neural Machine Translation, CoRR, 2015.\n\nmathrmscore(h_th_enc) = h_t^top W h_enc\n\nConstructors:\n\nAttnLuong(dec_units, enc_units; scale=true)\nAttnLuong(units; scale=true)\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.AttnDot","page":"API Reference","title":"NNHelferlein.AttnDot","text":"mutable struct AttnDot <: AttentionMechanism\n\nDot-product attention (without trainable parameters) according to the Luong, et al. (2015) paper.\n\nmathrmscore(h_th_enc) = h_t^top h_enc\n\nConstructors:\n\nAttnDot(; scale=true)\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.AttnLocation","page":"API Reference","title":"NNHelferlein.AttnLocation","text":"mutable struct AttnLocation <: AttentionMechanism\n\nLocation-based attention that only depends on the current decoder state h_t and not on the encoder states, according to the Luong, et al. (2015) paper.\n\nmathrmscore(h_t) = W h_t\n\nConstructors:\n\nAttnLocation(len, dec_units; scale=true)\n\nlen: maximum sequence length of the encoder to be considered       for attention. If the actual length of h_enc is bigger as the       length of α, attention factors for the remaining states are set to       0.0. If the actual length of h_enc is smaller than α, only the matching       attention factors are applied.\ndec_units: number of decoder units.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.AttnInFeed","page":"API Reference","title":"NNHelferlein.AttnInFeed","text":"mutable struct AttnInFeed <: AttentionMechanism\n\nInput-feeding attention that depends on the current decoder state h_t and the next input to the decoder i_t+1, according to the Luong, et al. (2015) paper.\n\nInfeed attention provides a semantic attention that depends on the next input token.\n\nmathrmscore(h_t i_t+1) = W_h h_t + W_i i_t+1 = W h_t i_t+1\n\nConstructors:\n\nAttnInFeed(len, dec_units, fan_in; scale=true)\n\nlen: maximum sequence length of the encoder to be considered       for attention. If the actual length of h_enc is bigger as the       length of α, attention factors for the remaining states are set to       0.0. If the actual length of h_enc is smaller than α, only the matching       attention factors are applied.\ndec_units: number of decoder units.\nfan_in: size of the decoder input.\n\nSignature:\n\nfunction (attn::AttnInFeed)(h_t, inp, h_enc; mask=nothing)\n\nh_t:    decoder hidden state. If h_t is a vector, its length           equals the number of decoder units. If it is a matrix,           h_t includes the states for a minibatch of samples and has           the size [units, mb].\ninp: next decoder input i_t+1           (e.g. next embedded token of sequence)\nh_enc:  encoder hidden states, 2d or 3d. If h_enc is a           matrix [units, steps] with the hidden states of all encoder steps.           If 3d: [units, mb, steps] encoder states for all minibatches.\nmask:   Optional mask for input states of shape [mb, steps].\n\n\n\n\n\n","category":"type"},{"location":"api/#Data-providers","page":"API Reference","title":"Data providers","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"DataLoader\nPartialIterator\nsplit_minibatches","category":"page"},{"location":"api/#NNHelferlein.DataLoader","page":"API Reference","title":"NNHelferlein.DataLoader","text":"abstract type DataLoader\n\nMother type for minibatch iterators.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.PartialIterator","page":"API Reference","title":"NNHelferlein.PartialIterator","text":"struct PartialIterator <: DataLoader\n\nThe PartialIterator wraps any iterator and will only iterate the states specified in the list indices. \n\nConstuctors\n\nPartialIterator(inner, indices; shuffle=true)\n\nType of the states must match the states of the wrapped iterator inner. A nothing element may be  given to specify the first iterator element.\n\nIf shuffle==true, the list of indices are shuffled every time the PartialIterator is started.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.split_minibatches","page":"API Reference","title":"NNHelferlein.split_minibatches","text":"function split_minibatches(it, at=0.8; shuffle=true)\n\nReturn 2 iterators od type PartialIterator which iterate only parts of the  states of the iterator it.  Be aware that the partial iterators will not contain copies of the data but instead forward the data provided by the iterator it.\n\nThe function can be used to split an iterator of minibatches into train-  and validation iterators, without copying any data. As the PartialIterator objects work with teh states of the inner iterator, it is important not to shuffle the inner iterator (in this case the  composition of the partial iterators would change!).\n\nArguments:\n\nit: Iterator to be splitted. The list of allowed states is created by       performing a full iteration once.\nat: Split point. The first returned iterator will include the given        fraction (default: 80%) of the states.\nshuffle: If true, the elements are shuffled at each restart of the iterator.\n\n\n\n\n\n","category":"function"},{"location":"api/#Tabular-data","page":"API Reference","title":"Tabular data","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Tabular data is normally provided in table form (csv, ods) row-wise, i.e. one sample per row. The helper functions can read the tables and generate Knet compatible iterators of minibatches.","category":"page"},{"location":"api/","page":"API Reference","title":"API Reference","text":"dataframe_read\ndataframe_minibatches\ndataframe_split\nmk_class_ids\nMBNoiser","category":"page"},{"location":"api/#NNHelferlein.dataframe_read","page":"API Reference","title":"NNHelferlein.dataframe_read","text":"dataframe_read(fname)\n\nRead a data table from an CSV-file with one sample per row and return a DataFrame with the data. (ODS-support is removed because of PyCall compatibility issues of the OdsIO package).\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.dataframe_minibatches","page":"API Reference","title":"NNHelferlein.dataframe_minibatches","text":"dataframe_minibatches(data::DataFrames.DataFrame; size=256, ignore=[], teaching=\"y\", \n                      verbose=1, o...)\n\nMake Knet-conform minibatches of type Knet.data from a dataframe with one sample per row.\n\nArguments:\n\nignore: defines a list of column names to be ignored\nteaching=\"y\": defines the column name with teaching input. Default is \"y\".               teaching is handled differently, depending on its type:               If Int, the teaching input is interpreted as               class ids and directly used for training (this assumes that               the values range from 1..n). If type is a String, values are               interpreted as class labels and converted to numeric class IDs               by calling mk_class_ids(). The list of valid lables and their               order can be created by calling mk_class_ids(data.y)[2].               If teaching is a scalar value, regression context is assumed,               and the value is used unchanged for training.\nverbose=1: if > 0, a summary of how the dataframe is used is echoed.\nother keyword arguments: all keyword arguments accepted by               Knet.minibatch() may be used.\n\nAllowed column definitions for ignore and teaching include names (as Strings), column names (as Symbols) or column indices (as Integer values).\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.dataframe_split","page":"API Reference","title":"NNHelferlein.dataframe_split","text":"function dataframe_split(df::DataFrames.DataFrame;\n                         teaching=\"y\", fr=0.2, balanced=true)\n\nSplit data, organised row-wise in a DataFrame into train and valid sets.\n\nArguments:\n\ndf: data\nteaching=\"y\": name or index of column with teaching input (y)\nfr=0.2: fraction of data to be used for validation\nshuffle=true: shuffle the rows of the dataframe.\nbalanced=true: if true, result datasets will be balanced by oversampling.             Returned datasets will be bigger as expected             but include the same numbers of samples for each class.\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.mk_class_ids","page":"API Reference","title":"NNHelferlein.mk_class_ids","text":"function mk_class_ids(labels)\n\nTake a list with n class labels for n instances and return a list of n class-IDs (of type Int) and an array of lables with the array index of each label corresponds its ID.\n\nArguments:\n\nlabels: List of labels (typically Strings)\n\nResult values:\n\narray of class-IDs in the same order as the input\narray of unique class-IDs ordered by their ID.\n\nExamples:\n\njulia> labels = [\"blue\", \"red\", \"red\", \"red\", \"green\", \"blue\", \"blue\"]\n7-element Array{String,1}:\n \"blue\"\n \"red\"\n \"red\"\n \"red\"\n \"green\"\n \"blue\"\n \"blue\"\n\njulia> mk_class_ids(labels)[1]\n7-element Array{Int64,1}:\n 1\n 3\n 3\n 3\n 2\n 1\n 1\n\n julia> mk_class_ids(labels)[2]\n3-element Array{String,1}:\n \"blue\"\n \"green\"\n \"red\"\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.MBNoiser","page":"API Reference","title":"NNHelferlein.MBNoiser","text":"type MBNoiser\n\nIterator to wrap any Knet.Data iterator of minibatches in  order to add random noise.     Each value will be multiplied with a random value form  Gaussian noise with mean=1.0 and sd=sigma.\n\nConstrutors:\n\nMBNoiser(mbs::Knet.Data, σ=1.0)\n\nmbs: iteraor with minibatches\nσ: standard deviation for the Gaussian noise\n\nExample:\n\ntrn = minibatch(x)\ntb_train!(mdl, Adam, MBNoiser(trn, σ=0.1))\n\n\n\n\n\n","category":"type"},{"location":"api/#Image-data","page":"API Reference","title":"Image data","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Images as data should be provided in directories with the directory names denoting the class labels. The helpers read from the root of a directory tree in which the first level of sub-dirs tell the class label. All images in the tree under a class label are read as instances of the respective class. The following tree will generate the classes daisy, rose and tulip:","category":"page"},{"location":"api/","page":"API Reference","title":"API Reference","text":"image_dir/\n├── daisy\n│   ├── 01\n│   │   ├── 01\n│   │   ├── 02\n│   │   └── 03\n│   ├── 02\n│   │   ├── 01\n│   │   └── 02\n│   └── others\n├── rose\n│   ├── big\n│   └── small\n└── tulip","category":"page"},{"location":"api/","page":"API Reference","title":"API Reference","text":"ImageLoader\nmk_image_minibatch\nget_class_labels\nimage2array\narray2image\narray2RGB","category":"page"},{"location":"api/#NNHelferlein.ImageLoader","page":"API Reference","title":"NNHelferlein.ImageLoader","text":"struct ImageLoader <: DataLoader\n    dir\n    i_paths\n    i_classes\n    classes\n    batchsize\n    shuffle\n    train\n    aug_pipl\n    pre_proc\n    pre_load\n    i_images\nend\n\nIterable image loader to provide minibatches of images as 4-d-arrays (x,y,rgb,mb).\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.mk_image_minibatch","page":"API Reference","title":"NNHelferlein.mk_image_minibatch","text":"function mk_image_minibatch(dir, batchsize; split=false, fr=0.2,\n                            balanced=false, shuffle=true, train=true,\n                            pre_load=false,\n                            aug_pipl=nothing, pre_proc=nothing)\n\nReturn one or two iterable image-loader-objects that provides minibatches of images. For training each minibatch is a tupel (x,y) with x: 4-d-array with the minibatch of data and y: vector of class IDs as Int.\n\nArguments:\n\ndir: base-directory of the image dataset. The first level of       sub-dirs are used as class names.\nbatchsize: size of minibatches\n\nKeyword arguments:\n\nsplit: return two iterators for training and validation\nfr: split fraction\nbalanced: return balanced data (i.e. same number of instances       for all classes). Balancing is achieved via oversampling\nshuffle: if true, shuffle the images everytime the iterator       restarts\ntrain: if true, minibatches with (x,y) Tuples are provided,       if false only x (for prediction)\npre_load: if true all images are loaded in advance;       otherwise images are loaded on demand durng training.       (option is not implemented yet!)\naug_pipl: augmentation pipeline for Augmentor.jl. Augmentation       is performed before the pre_proc-function is applied\npre_proc: function with preprocessing       and augmentation algoritms of type x = f(x). In contrast       to the augmentation that modifies images, is pre_proc       working on Arrays{Float32}.\npre_load=false: read all images from disk once when populating the       loader (requires loads of memory, but speeds up training).\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.get_class_labels","page":"API Reference","title":"NNHelferlein.get_class_labels","text":"function get_class_labels(d::DataLoader)\n\nExtracts a list of class labels from a DataLoader.\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.image2array","page":"API Reference","title":"NNHelferlein.image2array","text":"function image2array(img)\n\nTake an image and return a 3d-array for RGB and a 2d-array for grayscale images with the colour channels as last dimension.\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.array2image","page":"API Reference","title":"NNHelferlein.array2image","text":"function array2image(arr)\n\nTake a 3d-array with colour channels as last dimension or a 2d-array and return an array of RGB or of Gray as Image.\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.array2RGB","page":"API Reference","title":"NNHelferlein.array2RGB","text":"function array2RGB(arr)\n\nTake a 3d-array with colour channels as last dimension or a 2d-array and return always an array of RGB as Image.\n\n\n\n\n\n","category":"function"},{"location":"api/#Text-data","page":"API Reference","title":"Text data","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"WordTokenizer\nget_tatoeba_corpus\nsequence_minibatch\npad_sequence\ntruncate_sequence","category":"page"},{"location":"api/#NNHelferlein.WordTokenizer","page":"API Reference","title":"NNHelferlein.WordTokenizer","text":"mutable struct WordTokenizer\n    len\n    w2i\n    i2w\nend\n\nCreate a word-based vocabulary: every unique word of a String or a list of Strings is assigned to a unique number. The created object includes a list of words (i2w, ordered by their numbers) and a dictionary w2i with the words as keys.\n\nThe constants TOKEN_START, TOKEN_END, TOKEN_PAD and TOKEN_UNKOWN are exported.\n\nConstructor:\n\nfunction WordTokenizer(texts; len=nothing, add_ctls=true)\n\nWith arguments:\n\ntexts: AbstractArray or iterable collection of AbstractArrays to be       analysed.\nlen=nothing: maximum number of different words in the vocabulary.       Additional words in texts will be encoded as unknown. If nothing,       all words of the texts are included.\nadd_ctls=true: if true, control words are added in front of the vocabulary       (extending the maximum length by 4): \"<start>\"=>1, \"<end>\"=>2,       \"<pad>\"=>3 and \"<unknown>\"=>4.\n\nSignatures:\n\nfunction (t::WordTokenizer)(w::T; split_words=false, add_ctls=false)\n                            where {T <: AbstractString}\n\nEncode a word and return the corresponding number in the vocabulary or the highest number (i.e. \"<unknown>\") if the word is not in the vocabulary.\n\nThe encode-signature accepts the keyword arguments split_words and add_ctls. If split_words==true, the input is treated as a sentence and splitted into single words and an array of integer with the encoded sequence is returned. If add_ctls==true the sequence will be framed by <start> and <end> tokens.\n\nfunction (t::WordTokenizer)(i::Integer)\n\nDecode a word by returning the word corresponding to i or \"<unknown>\" if the number is out of range of the vocabulary.\n\nfunction (t::WordTokenizer)(s::AbstractArray{T}; add_ctls=false)\n                           where {T <: AbstractString}\n\nCalled with an Array of Strings the tokeniser splits the strings into words and returns an Array of Array{Integer} with each of the input strings represented by a sequence of Integer values.\n\nfunction (t::WordTokenizer)(seq::AbstractArray{T}; add_ctls=false)\n                                 where {T <: Integer}\n\nCalled with an Array of Integer values a single string  is returned with the decoded token-IDs as words (space-separated).\n\nBase Signatures:\n\n    function length(t::WordTokenizer)\n\nReturn the length of the vocab.\n\nExamples:\n\njulia> vocab = WordTokenizer([\"I love Julia\", \"They love Python\"]);\nJulia> vocab(8)\n\"Julia\"\n\njulia> vocab(\"love\")\n5\n\njulia> vocab.(split(\"I love Julia\"))\n3-element Array{Int64,1}:\n 5\n 6\n 8\n\njulia> vocab.i2w\n9-element Array{String,1}:\n \"<start>\"\n \"<end>\"\n \"<pad>\"\n \"<unknown>\"\n \"love\"\n \"I\"\n \"They\"\n \"Julia\"\n \"Python\"\n\njulia> vocab.w2i\nDict{String,Int64} with 9 entries:\n  \"I\"         => 6\n  \"<end>\"     => 2\n  \"<pad>\"     => 3\n  \"They\"      => 7\n  \"Julia\"     => 8\n  \"love\"      => 5\n  \"Python\"    => 9\n  \"<start>\"   => 1\n  \"<unknown>\" => 4\n\njulia> vocab.([7,5,8])\n3-element Array{String,1}:\n \"They\"\n \"love\"\n \"Julia\n\njulia> vocab.(\"I love Scala\", split_words=true)\n3-element Array{Int64,1}:\n 6\n 5\n 4\n\njulia> vocab.([6,5,4])\n3-element Array{String,1}:\n \"I\"\n \"love\"\n \"<unknown>\"\n\njulia> vocab(\"I love Python\", split_words=true, add_ctls=true)\n5-element Array{Int64,1}:\n 1\n 6\n 5\n 9\n 2\n\njulia> vocab([\"They love Julia\", \"I love Julia\"])\n2-element Array{Array{Int64,1},1}:\n [7, 5, 8]\n [6, 5, 8]\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.get_tatoeba_corpus","page":"API Reference","title":"NNHelferlein.get_tatoeba_corpus","text":"function get_tatoeba_corpus(lang; force=false,\n            url=\"https://www.manythings.org/anki/\")\n\nDownload and read a bilingual text corpus from Tatoeba (privided) by ManyThings (https://www.manythings.org). All corpi are English-Language-pairs with different size and quality. Considerable languages include:\n\nfra: French-English, 180 000 sentences\ndeu: German-English, 227 000 sentences\nheb: Hebrew-English, 126 000 sentences\npor: Portuguese-English, 170 000 sentences\ntur: Turkish-English, 514 000 sentences\n\nThe function returns two lists with corresponding sentences in both languages. Sentences are are not processed/normalised/cleaned, but exactly as provided by Tatoeba.\n\nThe data is stored in the package directory and only downloaded once.\n\nArguments:\n\nlang: languagecode\nforce=false: if true, the corpus is downloaded even if       a data file is already saved.\nurl: base url of ManyThings.\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.sequence_minibatch","page":"API Reference","title":"NNHelferlein.sequence_minibatch","text":"function sequence_minibatch(x, [y], batchsize; \n                            pad=NNHelferlein.TOKEN_PAD, \n                            seq2seq=true, pad_y=pad,\n                            x_padding=false,\n                            shuffle=true, partial=false)\n\nReturn an iterator of type DataLoader with (x,y) sequence minibatches from two lists of sequences.\n\nAll sequences within a minibatch in x and y are brought to the same length by padding with the token provided as pad.\n\nThe sequences are sorted by length before building minibatches in order to  reduce padding (i.e. sequences of similar length are combined to a minibatch). If the same sequence length is needed for all minibatches, the sequences must be truncted or padded before call of sequence_minibatch()  (see functions truncate_seqence() and pad_sequence()).\n\nArguments:\n\nx: List of sequences of Int\ny: List of sequences of Int or list of target values (i.e. teaching input)\nbatchsize: size of minibatches\npad=NNHelferlein.PAD_TOKEN,\npad_y=x: token, used for padding. The token must be compatible       with the type of the sequence elements. If pad_y is omitted, it is set        equal to pad_x.\nseq2seq=true: if true and y is provided, sequence-to-sequence minibatches are        created. Otherwise y is treated as scalar teaching input.\nshuffle=true: The minibatches are shuffled as last step. If false the minibatches        with short sequences will be at the beginning of the dataset.\npartial=false: If true, a partial minibatch will be created if necessray to        include all input data.\nx_padding=false: if true, pad sequences in x to make minibatches of the demanded size,        even if there are not       enougth sequences of the same length in x.       If false, partial minibatches are built (if partial == true) or remaining        sequneces are skipped (if partial == false).\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.pad_sequence","page":"API Reference","title":"NNHelferlein.pad_sequence","text":"function pad_sequence(s, len; token=NNHelferlein.TOKEN_PAD)\n\nStretch a sequence to length len by adding the padding token.\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.truncate_sequence","page":"API Reference","title":"NNHelferlein.truncate_sequence","text":"function truncate_sequence(s, len; end_token=nothing)\n\nTruncate a sequence to the length len.  If not isnothing(end_token), the last token of the sequenceis  overwritten by the token.\n\n\n\n\n\n","category":"function"},{"location":"api/#Training","page":"API Reference","title":"Training","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"tb_train!","category":"page"},{"location":"api/#NNHelferlein.tb_train!","page":"API Reference","title":"NNHelferlein.tb_train!","text":"function tb_train!(mdl, opti, trn, vld=nothing; epochs=1, split=nothing,\n                  lr_decay=nothing, lrd_steps=5, lrd_linear=false,\n                  l2=nothing, l1=nothing,\n                  eval_size=0.2, eval_freq=1,\n                  acc_fun=nothing,\n                  mb_loss_freq=100,\n                  checkpoints=nothing, cp_dir=\"checkpoints\",\n                  tb_dir=\"logs\", tb_name=\"run\",\n                  tb_text=\"\"\"Description of tb_train!() run.\"\"\",\n                  opti_args...)\n\nTrain function with TensorBoard integration. TB logs are written with the TensorBoardLogger.jl package. The model is updated (in-place) and the trained model is returned.\n\nArguments:\n\nmdl: model; i.e. forward-function for the net\nopti: Knet-stype optimiser type\ntrn: training data; iterator to provide (x,y)-tuples with       minibatches\nvld: validation data; iterator to provide (x,y)-tuples with       minibatches. Set to nothing, if not defined.\n\nKeyword arguments:\n\nOptimiser:\n\nepochs=1: number of epochs to train\nlr_decay=nothing: do a leraning rate decay if not nothing:       the value given is the final learning rate after lrd_steps       steps of decay (lr_decay may be bigger than lr; in this case       the leraning rate is increased).        lr_decay is only applied if both start learning rate       lr and final learning rate lr_decay are defined explicitly.       Example: lr=0.01, lr_decay=0.001 will reduce the lr from       0.01 to 0.001 during the training (by default in 5 steps).\nlrd_steps=5: number of learning rate decay steps. Default is 5, i.e.       modify the lr 4 times during the training (resulting in 5 different        leraning rates).\nlrd_linear=false: type of learning rate decay;       If false, lr is modified       by a constant factor (e.g. 0.9) resulting in an exponential decay.       If true, lr is modified by the same step size, i.e. linearly.\nl1=nothing: L1 regularisation; implemented as weight decay per       parameter\nl2=nothing: L2 regularisation; implemented as weight decay per       parameter\nopti_args...: optional keyword arguments for the optimiser can be specified       (i.e. lr, gamma, ...).\n\nModel evaluation:\n\nsplit=nothing: if no validation data is specified and split is a        fraction (between 0.0 and 1.0), the training dataset is splitted at the       specified point (e.g.: if split=0.8, 80% of the minibatches are used        for training and 20% for validation).\neval_size=0.2: fraction of validation data to be used for calculating       loss and accuracy for train and validation data during training.\neval_freq=1: frequency of evaluation; default=1 means evaluation is       calculated after each epoch. With eval_freq=10 eveluation is       calculated 10 times per epoch.\nacc_fun=nothing: function to calculate accuracy. The function       must implement the following signature: fun(model; data) where       data is an iterator that provides (x,y)-tuples of minibatches.       For classification tasks, accuracy from the Knet package is       a good choice. For regression a correlation or mean error       may be preferred.\nmb_loss_freq=100: frequency of training loss reporting. default=100       means that 100 loss-values per epoch will be logged to TensorBoard.       If mblossfreq is greater then the number of minibatches,       loss is logged for each minibatch.\ncheckpoints=nothing: frequency of model checkpoints written to disk.       Default is nothing, i.e. no checkpoints are written.       To write the model after each epoch with       name model use cpepoch=1; to write every second epochs cpepoch=2,        etc.\ncp_dir=\"checkpoints\": directory for checkpoints\n\nTensorBoard:\n\nTensorBoard log-directory is created from 3 parts: tb_dir/tb_name/<current date time>.\n\ntb_dir=\"logs\": root directory for tensorborad logs.\ntb_name=\"run\": name of training run. tb_name will be used as       directory name and should not include whitespace\ntb_text:  description       to be included in the TensorBoard log as text log.\n\n\n\n\n\n","category":"function"},{"location":"api/#Evaluation","page":"API Reference","title":"Evaluation","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"predict\npredict_top5\nhamming_dist\npeak_finder_acc","category":"page"},{"location":"api/#NNHelferlein.predict","page":"API Reference","title":"NNHelferlein.predict","text":"function predict(mdl, x; softmax=false)\n\nReturn the prediction for x.\n\nArguments:\n\nmdl: executable network model\nx: iterator providing minibatches       of input data\nsoftmax: if true or if model is of type Classifier the predicted       softmax probabilities are returned instead of raw       activations.\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.predict_top5","page":"API Reference","title":"NNHelferlein.predict_top5","text":"function predict_top5(mdl, x; top_n=5, classes=nothing)\n\nRun the model mdl for data in x and print the top 5 predictions as softmax probabilities.\n\nArguments:\n\ntop_n: print top n hits\nclasses: optional list of human readable class labels.\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.hamming_dist","page":"API Reference","title":"NNHelferlein.hamming_dist","text":"function hamming_dist(p, t; accuracy=false, \n                            ignore_ctls=false, vocab=nothing, \n                            start=nothing, stop=nothing, pad=nothing, unk=nothing)\n\n\nfunction hamming_acc(p, t; o...)\n\nfunction hamming_acc(mdl; data=data, o...)\n\nReturn the Hamming distance between two sequences or two minibatches of sequences. Predicted sequences p and teaching input sequences t may be of different length but the number of sequences in the minibatch must be the same.\n\nArguments:\n\np, t: n-dimensional arrays of type Int with predictions       and teaching input for a minibatch of sequences.       Shape of the arrays must be identical except of the first dimension       (i.e. the sequence length) that may differ between p and t.\naccuracy=false: if false, the mean Hamming distance in the minibatch       is returned (i.e. the average number of differences in the sequences).       If true, the accuracy is returned       for all not padded positions in a range (0.0 - 1.0).\nignore_ctls=false: a vocab is used to replace all '<start>, <end>, <unknwon>, <pad>'       tokens by <pad>. If true, padding and other control tokens are treated as       normal codes and are not ignored.\nvocab=nothing: target laguage vocabulary of type NNHelferlein.WordTokenizer.       If defined,       the padding token of vocab is used to mask all control tokens in the       sequences (i.e. '<start>, <end>, <unknwon>, <pad>').\nstart, stop, pad, unk: may be used to define individual control tokens.       default is nothing.\n\nDetails:\n\nThe function hamming_acc() is a shortcut to return the accuracy instead of the distance. The signature hamming_acc(mdl; data=data; o...) is for compatibility with acc functions called by train.\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.peak_finder_acc","page":"API Reference","title":"NNHelferlein.peak_finder_acc","text":"function peak_finder_acc(p, t; ret=:f1, verbose=0, \n                         tolerance=1, limit=0.5\n\nfunction peak_finder_acc(mdl; data=data, o...)\n\nCalculate an accuracy-like measure for data series consisting  mainly of zeros and rare peaks. The function counts the number of peaks in y detected by p  (true positives), peaks not detected (false negatives)  and the nnumber of peaks in p not present in y  (false positives).\n\nIt is assumed that peaks in y are marked by a single value higher as the limit (typically 1.0). Peaks in p may be  broader; and are defined as local maxima with a value above the limit. If the tolerance ist set to >0, it may happen that the peaks at the first  or last step are not evaluated (because evaluation stopss at  end-tolerance).\n\nIf requested, f1, G-mean and intersection over union  are calulated from the raw values .\n\nArguments:\n\np, t: Predictions and teaching input (i.e. y) are mini-batches of           1-d series of data. The sequence must be in the 1st dimension           (column). All other dims are treated as separate windows           of length size(p/t,1).\nret: return value as Symbol; one of        :peaks, :recall, :precision, :miss_rate, :f1,       :g_mean, :iou or :all.       If :all a named tuple is returned.\nvervose=0: if 0, no additional output is generated;       if 1, composite measures are printed to stdout;       if 2, all raw counts are printed.\ntolerance=1: peak finder tolerance: The peak is defined as correct       if it is detected within the tolerance.\nlimit=0.5: Only maxima with values above the limit are considered.\n\n\n\n\n\n","category":"function"},{"location":"api/#ImageNet-tools","page":"API Reference","title":"ImageNet tools","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"preproc_imagenet\npredict_imagenet\nget_imagenet_classes","category":"page"},{"location":"api/#NNHelferlein.preproc_imagenet","page":"API Reference","title":"NNHelferlein.preproc_imagenet","text":"function preproc_imagenet(img)\n\nImage preprocessing for pre-trained ImageNet examples. Preprocessing includes\n\nbring RGB colour values into a range 0-255\nstandardise of colour values by substracting mean colour values   (103.939, 116.779, 123.68) from RGB\nchanging colour channel sequence from RGB to BGR\n\nResize is not done, because this may be part of the augmentation pipeline.\n\nExamples:\n\nThe function can be used with the image loader; for prediction with a trained model as:\n\npipl = CropRatio(ratio=1.0) |> Resize(224,224)\nimages = mk_image_minibatch(\"./example_pics\", 16;\n                    shuffle=false, train=false,\n                    aug_pipl=pipl,\n                    pre_proc=preproc_imagenet)\n\nAnd for training something like:\n\npipl = Either(1=>FlipX(), 1=>FlipY(), 2=>NoOp()) |>\n       Rotate(-5:5) |>\n       ShearX(-5:5) * ShearY(-5:5) |>\n       RCropSize(224,224)\n\ndtrn, dvld = mk_image_minibatch(\"./example_pics\", 16;\n                    split=true, fr=0.2, balanced=false,\n                    shuffle=true, train=true,\n                    aug_pipl=pipl,\n                    pre_proc=preproc_imagenet)\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.predict_imagenet","page":"API Reference","title":"NNHelferlein.predict_imagenet","text":"function predict_imagenet(mdl, x; top_n=5)\n\nPredict the ImageNet-class of images from the predefined list of class labels.\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.get_imagenet_classes","page":"API Reference","title":"NNHelferlein.get_imagenet_classes","text":"function get_imagenet_classes()\n\nReturn a list of all 1000 ImageNet class labels.\n\n\n\n\n\n","category":"function"},{"location":"api/#Other-utils","page":"API Reference","title":"Other utils","text":"","category":"section"},{"location":"api/#Layers-and-helpers-for-transformers","page":"API Reference","title":"Layers and helpers for transformers","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"PositionalEncoding\nmk_padding_mask\nmk_peek_ahead_mask\ndot_prod_attn\nMultiHeadAttn\nseparate_heads\nmerge_heads","category":"page"},{"location":"api/#NNHelferlein.PositionalEncoding","page":"API Reference","title":"NNHelferlein.PositionalEncoding","text":"struct PositionalEncoding <: Layer\n\nPositional encoding layer. Only sincos-style (according to Vaswani, et al., NIPS 2017) is implemented.\n\nThe layer takes an array of any any number of dimensions (>=2), calculates the Vaswani-2017-style positional encoding and adds the encoding to each plane of the array.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.mk_padding_mask","page":"API Reference","title":"NNHelferlein.mk_padding_mask","text":"function mk_padding_mask(x; pad=TOKEN_PAD, add_dims=false)\n\nMake a padding mask; i.e. return an Array of type KnetArray{Float32} (or Array{Float32}) similar to x but with two additional dimension of size 1 in the middle (this will represent the 2nd seq_len and the number of heads) in multi-head attention and the value 1.0 at each position where x is pad and 0.0 otherwise.\n\nThe function can be used for creating padding masks for attention mechanisms.\n\nArguments:\n\nx: Array of sequences (typically a matrix with ncols sequences   of length nrows)\npad: value for the token to be masked\nadd_dims: if true, 2 additional dimensions are inserted to    return a 4-D-array as needed for transformer architectures. Otherwise   the size of teh returned array is similar to x.\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.mk_peek_ahead_mask","page":"API Reference","title":"NNHelferlein.mk_peek_ahead_mask","text":"function mk_peek_ahead_mask(x; dim=1)\n\nReturn a matrix of size [n_seq, n_seq] filled with 1.0 and the uppper triangle set to 0.0. Type is KnetArray{Float32} in GPU context, Array{Float32} otherwise. The matrix can be used as peek-ahead mask in transformers.\n\ndim=1 specifies the dimension in which the sequence length is represented. For un-embedded data this is normally 1, i.e. the shape of x is [nseq, nmb]. After embedding the shape probably is [depth, nseq, nmb].\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.dot_prod_attn","page":"API Reference","title":"NNHelferlein.dot_prod_attn","text":"function dot_prod_attn(q, k, v; mask=nothing)\n\nGeneric scaled dot product attention following the paper of Vaswani et al., (2017), Attention Is All You Need.\n\nArguments:\n\nq: query of size [depth, n_seq_q, ...]\nk: key of size [depth, n_seq_v, ...]\nv: value of size [depth, n_seq_v, ...]\nmask: mask for attention factors may have different shapes but must be       broadcastable for addition to the scores tensor (which as the same size as       alpha [n_seq_v, n_seq_q, ...]). In transformer context typical masks are one of:       padding mask of size [n_seq_v, ...] or a peek-ahead mask of size [n_seq_v, n_seq_v]       (which is only possible in case of self-attention when all seqencee lengths       are identical).\n\nq, k, v must have matching leading dimensions (i.e. same depth or embedding). k and v must have the same sequence length.\n\nReturn values:\n\nc: context as alpha-weighted sum of values with size [depth, nseqv, ...]\nalpha: attention factors of size [nseqv, nseqq, ...]\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.MultiHeadAttn","page":"API Reference","title":"NNHelferlein.MultiHeadAttn","text":"struct MultiHeadAttn <: Layer\n\nMulti-headed attention layer, designed following the Vaswani, 2017 paper.\n\nConstructor:\n\nMultiHeadAttn(depth, n_heads)\n\ndepth: Embedding depth\nn_heads: number of heads for the attention.\n\nSignature:\n\nfunction(mha::MultiHeadAttn)(q, k, v; mask=nothing)\n\nq, k, v are 3-dimensional tensors of the same size ([depth, seqlen, nminibatch]) and the optional mask must be of  size [seqlen, nminibatch] and mark masked positions with 1.0.\n\n\n\n\n\n","category":"type"},{"location":"api/#NNHelferlein.separate_heads","page":"API Reference","title":"NNHelferlein.separate_heads","text":"function separate_heads(x, n)\n\nHelper function for multi-headed attention mechanisms:  an additional second dimension is added to a tensor of minibatches by splitting the first (i.e. depth).\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.merge_heads","page":"API Reference","title":"NNHelferlein.merge_heads","text":"function merge_heads(x)\n\nHelper to merge the result of multi-headed attention back to full depth .\n\n\n\n\n\n","category":"function"},{"location":"api/#Utils-for-array-manipulation","page":"API Reference","title":"Utils for array manipulation","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"crop_array\nblowup_array\nrecycle_array\nde_embed","category":"page"},{"location":"api/#NNHelferlein.crop_array","page":"API Reference","title":"NNHelferlein.crop_array","text":"function crop_array(x, crop_sizes)\n\nCrop a n-dimensional array to the given size. Cropping is always centered (i.e. a margin is removed).\n\nArguments:\n\nx: n-dim AbstractArray\ncrop_sizes: Tuple of target sizes to which the array is cropped.       Allowed values are Int or :. If crop_sizes defines less       dims as x has, the remaining dims will not be cropped (assuming :).       If a demanded crop size is bigger as the actual size of x,       it is ignored.\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.blowup_array","page":"API Reference","title":"NNHelferlein.blowup_array","text":"function blowup_array(x, n)\n\nBlow up an array x with an additional dimension and repeat the content of the array n times.\n\nArguments:\n\nx: Array of any dimension\nn: number of repeats. ´n=1´ will return an\n\narray with an additional dimension of size 1.\n\nExamples:\n\njulia> x = [1,2,3,4]; blowup_array(x, 3)\n4×3 Array{Int64,2}:\n 1  1  1\n 2  2  2\n 3  3  3\n 4  4  4\n\njulia> x = [1 2; 3 4]; blowup_array(x, 3)\n2×2×3 Array{Int64,3}:\n[:, :, 1] =\n 1  2\n 3  4\n\n[:, :, 2] =\n 1  2\n 3  4\n\n[:, :, 3] =\n 1  2\n 3  4\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.recycle_array","page":"API Reference","title":"NNHelferlein.recycle_array","text":"function recycle_array(x, n; dims=dims(x))\n\nRecycle an array x along the specified dimension  (default the last dimension) and repeat the content of the array n times. The number of dims stays unchanged, but the array valueas are repeated n times.\n\nArguments:\n\nx: Array of any dimension\nn: number of repeats. ´n=1´ will return an unchanged       array\ndims: dimension to be repeated.\n\nExamples:\n\njulia> recycle_array([1,2],3)\n6-element Array{Int64,1}:\n 1\n 2\n 1\n 2\n 1\n 2\n\njulia> x = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> recycle_array(x,3)\n2×6 Array{Int64,2}:\n 1  2  1  2  1  2\n 3  4  3  4  3  4\n\njulia> recycle_array([1 2 3],3, dims=1)\n3x3 Array{Int64,2}:\n 1 2 3\n 1 2 3\n 1 2 3\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.de_embed","page":"API Reference","title":"NNHelferlein.de_embed","text":"function de_embed(x; remove_dim=false)\n\nReplace the maximum of the first dimension of an n-dimensional array by its index (aka argmax()). If remove_dim is true, the result has the first dimension removed; otherwise the returned array has the first dimension with size 1  (default).\n\nExamples:\n\n> x = [1 1 1\n       2 1 1\n       1 2 1\n       1 1 2]\n> de_embed(x)\n1×3 Matrix{Int64}:\n 2  3  4\n\n> de_embed(x, remove_dim=true)\n3-element Vector{Int64}:\n 2\n 3\n 4\n\n\n\n\n\n","category":"function"},{"location":"api/#Utils-for-fixing-types-in-GPU-context","page":"API Reference","title":"Utils for fixing types in GPU context","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"init0\nconvert2CuArray\nemptyCuArray","category":"page"},{"location":"api/#NNHelferlein.init0","page":"API Reference","title":"NNHelferlein.init0","text":"function init0(siz...)\n\nInitialise a vector or array of size siz with zeros. If a GPU is detected type of the returned value is KnetArray{Float32}, otherwise Array{Float32}.\n\nExamples:\n\njulia> init0(2,10)\n2×10 Array{Float32,2}:\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n\n julia> init0(0,10)\n 0×10 Array{Float32,2}\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.convert2CuArray","page":"API Reference","title":"NNHelferlein.convert2CuArray","text":"function convert2CuArray(x, innerType=Float32)\nfunction convert2KnetArray(x, innerType=Float32)\n\nConvert an array x to a CuArray{Float32} or whatever specified as innerType only in GPU context (if CUDA.functional()) or to an Array{Float32} otherwise. By converting, the data is copied to the GPU.\n\nconvert2KnetArray() is kept as an alias for backward compatibility.\n\n\n\n\n\n","category":"function"},{"location":"api/#NNHelferlein.emptyCuArray","page":"API Reference","title":"NNHelferlein.emptyCuArray","text":"function emptyCuArray(size...=(0,0);innerType=Float32)\nfunction emptyKnetArray(size...=(0,0);innerType=Float32)\n\nReturn an empty CuArray with the specified dimensions. The  array may be empty (i.e. one dimension 0) or elements will be undefined.\n\nBy default an empty matrix is returned.\n\nExamples:\n\n>>> emptyKnetArray(0,0)\n0×0 Knet.KnetArrays.KnetMatrix{Float32}\n\n>>> emptyKnetArray()\n0×0 Knet.KnetArrays.KnetMatrix{Float32}\n\n>>> emptyKnetArray(0)\n0-element Knet.KnetArrays.KnetVector{Float32}\n\n\n\n\n\n","category":"function"},{"location":"license/","page":"License","title":"License","text":"The NNHelferlein.jl package is licensed under the MIT License:","category":"page"},{"location":"license/","page":"License","title":"License","text":"Copyright (c) 2021 Andreas Dominik, THM, Gießen, Germany","category":"page"},{"location":"license/","page":"License","title":"License","text":"Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:","category":"page"},{"location":"license/","page":"License","title":"License","text":"The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.","category":"page"},{"location":"license/","page":"License","title":"License","text":"THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","category":"page"},{"location":"examples/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Examples may be used as templates for new projects...     All examples are at GitHub/examples:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Simple MLP: A simple multi-layer perceptron for MNIST classification, build with Knet and Helferlein-types in just one line of code (or so).","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Simple LeNet: A simple LeNet for MNIST classification,  build with help of the Helferlein layers in just two (ok: long) lines of code. ","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Vanilla Autoencoder: A simple autoencoder design with help of Knet in Helferlein-style.\nConvolutional Autoencoder: A convolutional autoencoder design with help of Knet in Helferlein-style.\nVariational Autoencoder: Example for a simple VAE utilising the NNHelferlein-type VAE and demonstrating the fascinating regularisation of a VAE.\nSimple sequence-to-sequence network: Simple s2s network to demonstrate how to setup macghine translation with  a rnn.\nSequence-to-sequence RNN for machine translation: RNN to demonstrate how to setup machine translation with  a bidirectional encoder RNN and attention.\nRNN Sequence tagger for annotation of ECGs: RNN to demonstrate how to set-up a sequence tagger to detect heart beats. Only one layer with 8 units is necessary to achieve almost 100% correct predictions.  The example includes the definition on peephole LSTMs to display how to integrate non-standard rnn-units with the NNHelfrelein framework.\nPretrained VGG16: The notebook shows the import of a pretrained VGG16 model from Tensorflow/Keras into a Knet-style CNN and its application to example images utilising the Helferlein imagenet-utilities.\nTransformer for machine translation: A simple transformer architecture is set up according to the 2017 Vaswani paper Attention is All You Need with help of  NNHelferlein-utils.","category":"page"},{"location":"overview/#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"The section provides a brief overview of the functionality provided by NNHelferlen. For more details, please visit the API-Section.","category":"page"},{"location":"overview/#Neural-network-definitions","page":"Overview","title":"Neural network definitions","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"The abstract type DNN provides signatures to be called as","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"(m::DNN)(x): evaluate x (sample or minibatch)\n(m::DNN)(x,y): evaluate x and calculate the loss\n(m::DNN)(d): return the mean loss for a dataset, if d is an iterator               of type Knet.Data or NNHelferlen.DataLoader\n(m::DNN)((x,y)): return the mean loss for a x,y-tuple.","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"Explicit signatures exist for types Classifier and Regressor with negative log-likelihood and square loss as loss, respectively. For variational autoencoders the type VAE exists.","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"The type Chain wraps a list of layers that are executed sequentially.","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"A network summary can be printed with summary(mdl::DNN) and a more detailed list of all layers with print_network(mdl::DNN).","category":"page"},{"location":"overview/#Layer-definitions","page":"Overview","title":"Layer definitions","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"Several layers are predefined with executable signatures:","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"MLPs: different flavours of the simple layer:       Dense: default layer for a vector (i.e. sample)          or matrix (i.e. mininbatch) as input with logistic          actvation as default.               Linear: TensorFlow-style layer to process high-dimensional         arrays and identity as default activation.       Embed: embedding layer that adds a first dimension with the          embeddings to the input.\nConvolutional NNs: to build CNNs Conv, DeConv, Pool       UnPool and Flat             layers are provided with standard functionality.       The utilitys include methods for array manipulation, such as       clipping arrays or adding dimensions.\nRecurrent Layers: a Recurrent layer is defined as wrapper        around the basic Knet RNN type.\nOthers: additional layers include (please see the API-section for       a complete list!):       Softmax, Dropout, trainable BatchNorm, trainable LayerNorm.","category":"page"},{"location":"overview/#Attention-Mechanisms","page":"Overview","title":"Attention Mechanisms","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"Some attention mechanisms are implemented for use in sequence-to-sequence networks. If possible projections of values are  precomputed to reduce computational cost:","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"AttnBahdanau: concat- or additive-style attention according to       Bahdanau, 2015.\nAttnLuong: multiplicative-or general-stype attention according to       Luong, 2015.\nAttnDot: dot-product-style attention according to       Luong, 2015.\nAttnLocation: dot-product-style attention according to       Luong, 2015.\nAttnInFeed: input-feeding attention according to       Luong, 2015.","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"A generalised dot-product attention can be computed from (Query, Key, Value) tuple: dot_prod_attn(q, k, v).","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"Helpers for transformer networks include functions for positional encoding, generating padding- and peek-akead-masks and computing scaled multi-headed attention, according to Vaswani, 2017.","category":"page"},{"location":"overview/#Data-provider","page":"Overview","title":"Data provider","text":"","category":"section"},{"location":"overview/#Image-data","page":"Overview","title":"Image data","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"The function mk_image_minibatch() can be used to create an iterator over images, organised in directories, with the first directory-level as class labels.","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"Helper functions (such as image2array(), array2image(), array2RGB()) can be used to transform image data to arrays. Imagenet-style preprocessing can be achieved with preproc_imagenet(), readable Imagenet class labels of the top predictions are printed by predict_imagenet().","category":"page"},{"location":"overview/#DataFrames","page":"Overview","title":"DataFrames","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"Helpers for tabular date include:","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"dataframe_read: read a csv-file and return a DataFrame\ndataframe_split: split tabular data in a DataFrame into train and               validation data; optionally with balancing.\ndataframe_minibatches: data provider to turn tabular data from               a DataFrame (with one sample per row)               into a Knet-like iterator of minibatches of type Knet.Data.\nmk_class_ids(labels): may be used to turn class label strings into               class-IDs.","category":"page"},{"location":"overview/#Texts-and-NLP","page":"Overview","title":"Texts and NLP","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"Some utilities are provided for NLP data handling:","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"WordTokenizer: a simple tool to encode words as ids.       The type comes with signatures to en- and decode in both directions.\nget_tatoeba_corpus: download dual-language corpi and provide       corresponding lists of sentences in two languages.","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"sequence_minibatch() function returns an iterator to sequence or sequence-to-secuence minibatches. Also helpers for padding and truncating sequences are provided.","category":"page"},{"location":"overview/#Working-with-pretrained-networks","page":"Overview","title":"Working with pretrained networks","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"Layers of pre-trained models can be created from TensorFlow HDF5-parameter files. It is possible to build a network from any pretrained TensorFlow model by importing the parameters by HDF5-constructors for the layers Dense, Conv. The flatten-layer PyFlat allows for Python-like row-major-flattening, necessary to make sure, that the parameters of an imported layer after flattening are in the correct order.","category":"page"},{"location":"overview/#Training","page":"Overview","title":"Training","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"Although Knet-style is to avoid havyweight interfaces and train networks with lightweight and flexible optimisers, a train interface is added that provides TensorBoard logs with online reporting of minibatch loss, training and validation loss and accuracy.","category":"page"},{"location":"overview/#Utilities","page":"Overview","title":"Utilities","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"A number of additional utilities is included. Please have a look at the utilities section of the API documentation.","category":"page"},{"location":"#NNHelferlein-ADo's-Neural-Networks-Little-Helpers","page":"Introduction","title":"NNHelferlein - ADo's Neural Networks Little Helpers","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The package provides helpers and utilities mainly to be used with the Knet package to build artificial neural networks.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The package follows mainly the Knet-style; i.e. all networks can be trained with the Knet-iterators, all layers can be used together with Knet-style quickly-self-written layers, all Knet-networks can be trained with tb_train(), all data providers can be used together, ...","category":"page"},{"location":"#Installation","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"For installation please refer to the README @github: https://github.com/andreasdominik/NNHelferlein.jl","category":"page"},{"location":"#First-Steps","page":"Introduction","title":"First Steps","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"NNHelferlein provides quick and easy definition, training and validation of neural network chains.","category":"page"},{"location":"#Symbolic-API","page":"Introduction","title":"Symbolic API","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The Keras-like symbolic API allows for building simple Chains, Classifiers and Regressors from predefined or self-written  layers or functions.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"A first example may be the famous MNIST handwriting recognition  data. Let us assume the data is already loaded in minibatches  in a dtrn iterator and a MLP shall do the job.  The remainder is as little as:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"mlp = Classifier(Dense(784, 256),\n                 Dense(256, 64), \n                 Dense(64, 10, actf=identity)))\n\n\nmlp = tb_train!(mlp, Adam, dtrn, epochs=10, split=0.8,\n                acc_fun=accuracy, eval_size=0.2)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Chains may be built of type Chain, Classifier or Regressor. Simple Chains bring only a signature model(x) to compute  forward computations of a data-sample, a minibatch of data as well as many minibatches of data (the dataset -here: dtrn- must be an iterable object that provides one minibatch on every call).","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Classifiers and Regressors in addition already come with signatures for loss calculation of (x,y)-minibatches (model(x,y))  with crossentropy loss (i.e. negative log-likelihood) and square-loss respectively. This is why  for both types the last layer must not have an activation function (the Helferlein Dense-layer comes with a logistic/sigmoid activation by default; alternatively the Linear-layer can be used that have  no default activation function).","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The function tb_train!() updates the model with the possibility to specify optimiser, training and validation data or an optional split ratio to perform a random  training/validation split. The function offers a multitude of  other options (see the API-documentation for details) and writes tensorboard log-files that allow for online monitoring of the  training progress during training via tensorboard.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"A second way to define a model is the add_layer!()-syntax, here shown for a simple LeNet-like model for the same problem:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"lenet = Classifier()\n\nadd_layer!(lenet, Conv(5,5,1,20))\nadd_layer!(lenet, Pool())\nadd_layer!(lenet, Conv(5,5,20,50))\nadd_layer!(lenet, Pool())\nadd_layer!(lenet, Flat())\nadd_layer!(lenet, Dense(800,512))\nadd_layer!(lenet, Dense(512,10, actf=identity))\n\nmlp = tb_train!(lenet, Adam, dtrn, epochs=10, split=0.8,\n                acc_fun=accuracy, eval_size=0.2)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Of course, both possibilities can be combined as desired; the following code gives a similar model:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"filters = Chain(Conv(5,5,1,20),\n                Pool(),\n                Conv(5,5,20,50),\n                Pool())\nclassif = Chain(Dense(800,512),\n                Dense(512,10, actf=identity))\n\nlenet2 = Classifier(filters, \n                   Flat())\nadd_layer!(lenet2, classif)\n\nmlp = tb_train!(lenet2, Adam, dtrn, epochs=10, split=0.8,\n                acc_fun=accuracy, eval_size=0.2)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Models can be summarised with the print_network()-helper:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> print_network(lenet)\nNeural network summary:\nClassifier with 7 layers,                                       440812 params\nDetails:\n \n    Conv layer 1 → 20 (5,5) with relu,                             520 params\n    Pool layer,                                                      0 params\n    Conv layer 20 → 50 (5,5) with relu,                          25050 params\n    Pool layer,                                                      0 params\n    Flat layer,                                                      0 params\n    Dense layer 800 → 512 with sigm,                            410112 params\n    Dense layer 512 → 10 with identity,                           5130 params\n \nTotal number of layers: 7\nTotal number of parameters: 440812","category":"page"},{"location":"#Free-model-definition","page":"Introduction","title":"Free model definition","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Another way of model definition gives the full freedom  to define a forward function as pure Julia code.  In the Python world this type of definition is often referred to   as the functional API - in the Julia world we hesitate calling  it an API,  because at the end of the day all is just out-of-the-box Julia! Each model just needs a type, able to store all parameters,  a signature model(x) to compute a forward run and predict the result and a signature model(x,y) to calculate the loss.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"For the predefined Classifier and Regressor types the signatures are  predefined - for own models, this can be easily done in a few lines of code.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The LeNet-like example network for MNIST may be written as:","category":"page"},{"location":"#The-type-and-constructor:","page":"Introduction","title":"The type and constructor:","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"struct LeNet\n    drop1\n    conv1\n    pool1\n    conv2\n    pool2\n    flat\n    drop2\n    mlp\n    predict\n    function LeNet(;drop=0.2)\n        return new(Dropout(drop),\n                   Conv(5,5,1,20),\n                   Pool(),\n                   Conv(5,5,20,50),\n                   Pool(),\n                   Flatten(),\n                   Dropout(drop)\n                   Dense(800, 512),\n                   Dense(512, 10, actf=identity))\nend","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Of course the model may be configured by giving the constructor more parameters. Also the code may be written better organised by combining layers to Chains.","category":"page"},{"location":"#The-forward-signature:","page":"Introduction","title":"The forward signature:","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"function (nn::LeNet)(x)\n    x = drop1(x)\n    x = conv1(x)\n    x = pool1(x)\n    x = conv2(x)\n    x = pool2(x)\n    x = flat(x)\n    x = drop2(x)\n    x = mlp(x)\n    x = predict(x)\n    return x\nend","category":"page"},{"location":"#The-loss-signature:","page":"Introduction","title":"The loss-signature:","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"function (nn::LeNet)(x,y)\n    return nll(nn(x), y)\nend","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Here we use the Knet.nll() function to calculate the crossentropy. ","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"That's it!","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Belive it or not - that's all you need to leave the  limitations of the Python world behind and playfully design any  innovative neural network in just a couple of lines of Julia code.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The next step is to have a look at the examples in the GitHub repo:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Pages = [\n    \"examples.md\"\n    ]\nDepth = 2","category":"page"},{"location":"#Overview","page":"Introduction","title":"Overview","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Pages = [\n    \"overview.md\"\n    ]\nDepth = 2","category":"page"},{"location":"#API-Reference","page":"Introduction","title":"API Reference","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Pages = [\n    \"api.md\"\n    ]\nDepth = 2","category":"page"},{"location":"#Index","page":"Introduction","title":"Index","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"","category":"page"}]
}
